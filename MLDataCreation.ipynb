{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#import tensorflow_datasets as tfds\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import urllib.request\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json \n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import glob\n",
    "import cv2\n",
    "role = get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'deeplens-imageclass'\n",
    "session = boto3.Session()\n",
    "s3 = session.resource('s3')\n",
    "my_bucket = s3.Bucket(bucket_name)\n",
    "region = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[session.region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tfds.load('celeb_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_attributes(bucket, key):\n",
    "    rekognition = session.client('rekognition', region)\n",
    "    response = rekognition.detect_faces(\n",
    "            Image = {\n",
    "                \"S3Object\": {\n",
    "                    \"Bucket\": bucket,\n",
    "                    \"Name\": key\n",
    "                }\n",
    "            },\n",
    "            Attributes = [\n",
    "                \"ALL\"\n",
    "            ]\n",
    "    )\n",
    "    return response['FaceDetails']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_all_images(image):\n",
    "    key = image.key\n",
    "    filename = key.split(\"/\")[2]\n",
    "    filename = filename.split(\".\")[0]\n",
    "    filepath = \"data/imgdata-responses/{}.json\".format(filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        print(key, \"processed image\")\n",
    "    else:\n",
    "        for category in detect_attributes(bucket_name, key):\n",
    "            with open(filepath, 'w') as outfile:\n",
    "                json.dump(category, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_images = my_bucket.objects.filter(Prefix='imgdata-raw')\n",
    "for image in array_images:\n",
    "    my_key = image.key\n",
    "    end_my_key = my_key[-4:]\n",
    "    if end_my_key == \".jpg\":\n",
    "        data_key = my_key.split(\"/\")[2]\n",
    "        file_pos = \"data/\" + data_key\n",
    "        bucket.download_file(my_key, file_pos)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ThreadPool(4)\n",
    "my_map = pool.map(detect_all_images, array_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for image in array_images:\n",
    "    my_key = image.key\n",
    "    end_key = my_key[-4:]\n",
    "    if end_key == \".jpg\":\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face_border(f_cascade, colored_image):\n",
    "    scale_factor = 1.1\n",
    "    copy_image = np.copy(colored_image)\n",
    "    gray_image = cv2.cvtColor(copy_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = f_cascade.detectMultiScale(gray_image, scale_factor, minNeighbors = 5)\n",
    "    num_faces = len(faces)\n",
    "    if num_faces == 1:\n",
    "        (x, y, width, height) = faces[0]\n",
    "        rec_face = copy_image[x : x + width, y : y + height]\n",
    "        return rec_face\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "    all_images = glob.glob('data/imgdata-raw/*.jpg')\n",
    "    for image_file in all_images:\n",
    "        my_image = cv2.imread(image_file)\n",
    "        rename_image_file = image_file.replace('imgdata-raw', 'imgdata-resize')\n",
    "        rec_my_image = find_face_border(face_cascade, my_image)\n",
    "        num_rec_my_image = len(rec_my_image)\n",
    "        if num_rec_my_image > 0:\n",
    "            resize_my_image = cv2.resize(rec_my_image, (224, 224))\n",
    "            cv2.imwrite(rename_image_file, resize_my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emotions():\n",
    "    train_file = open('training-file.lst', 'w')\n",
    "    test_file = open('test-file.lst', 'w')\n",
    "    response_counter = 0\n",
    "    all_responses = glob.glob('data/imgdata-responses/*.json')\n",
    "    dict_emotion = {\n",
    "    \n",
    "    }\n",
    "    for filename in all_responses:\n",
    "        response_counter = response_counter + 1\n",
    "        spec_file = filename.split('/')[2]\n",
    "        spec_file = spec_file.split('.')[0]\n",
    "        image_spec_file = 'data/imgdata-resize/{}.jpg'.format(spec_file)\n",
    "        if os.path.isfile(image_spec_file):\n",
    "            data = json.load(open(filename))\n",
    "            # smile and emotions for later use, for now just single emotion output\n",
    "            smile = False \n",
    "            emotions = []\n",
    "            emotion = 'None'\n",
    "            for i in range(7):\n",
    "                emotions.append(0)\n",
    "            if data['Smile']['Value'] or data['Smile']['Confidence'] < 89:\n",
    "                smile = True\n",
    "            emotion_data = data['Emotions']\n",
    "            for response_emotion in emotion_data:\n",
    "                emotion_type = response_emotion['Type']\n",
    "                emotion_confidence = response_emotion['Confidence']\n",
    "                if emotion_confidence > 70:\n",
    "                    if emotion_type == 'HAPPY':\n",
    "                        emotions[0] = 1 \n",
    "                        continue\n",
    "                    elif emotion_type == 'CALM':\n",
    "                        emotions[1] = 1\n",
    "                        continue\n",
    "                    elif emotion_type == 'ANGRY':\n",
    "                        emotions[2] = 1\n",
    "                        continue\n",
    "                    elif emotion_type == 'SAD':\n",
    "                        emotions[3] = 1\n",
    "                        continue\n",
    "                    elif emotion_type == 'SUPRISED':\n",
    "                        emotions[4] = 1\n",
    "                        continue\n",
    "                    elif emotion_type == 'CONFUSED':\n",
    "                        emotions[5] = 1\n",
    "                        continue\n",
    "                    elif emotion_type == 'DISGUSTED':\n",
    "                        emotions[6] = 1\n",
    "                        continue\n",
    "            highest_emotion = -1\n",
    "            for response_emotion in emotion_data:\n",
    "                emotion_type = response_emotion['Type']\n",
    "                emotion_confidence = response_emotion['Confidence']\n",
    "                if emotion_confidence > highest_emotion:\n",
    "                    highest_emotion = emotion_confidence\n",
    "                    emotion = emotion_type\n",
    "            dict_emotion[image_spec_file] = \"Happy\" if smile else \"Not Happy\"\n",
    "            if response_counter < 9928:\n",
    "                train_file.write(\"{} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {} \\n\".format(\n",
    "                    emotion, smile, emotions[0], emotions[1], emotions[2], emotions[3], emotions[4], emotions[5], emotions[6], filename))        \n",
    "            else:\n",
    "                test_file.write(\"{} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {:-d} \\t {} \\n\".format(\n",
    "                    emotion, smile, emotions[0], emotions[1], emotions[2], emotions[3], emotions[4], emotions[5], emotions[6], filename))\n",
    "    with open('emotion-dictionary.json', 'w') as emotion_json_file:\n",
    "        json.dump(dict_emotion, emotion_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_emotions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_string = 'emotion-dictionary.json'\n",
    "dict_emotion_file = open(dict_string, 'r')\n",
    "dict_emotion = json.load(dict_emotion_file)\n",
    "dict_emotion_list = list(dict_emotion)\n",
    "happy = 0\n",
    "not_happy = 0\n",
    "for emotion in dict_emotion_list:\n",
    "    if dict_emotion[emotion] == \"Happy\":\n",
    "        happy += 1\n",
    "    else:\n",
    "        not_happy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11646\n"
     ]
    }
   ],
   "source": [
    "my_json_file = 'emotion-dictionary.json'\n",
    "my_path = os.path.isfile(my_json_file)\n",
    "if my_path:\n",
    "    mine = json.load(open(my_json_file))\n",
    "    print(len(mine))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
